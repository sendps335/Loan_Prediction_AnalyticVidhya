# -*- coding: utf-8 -*-
"""Loan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rkxTCiRBgxL1ZkmxFf0VXTG7vOpuCXGv
"""

import pandas as pd
import numpy as np
import seaborn as sns
from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score,f1_score
from sklearn.linear_model import LogisticRegression
from sklearn import metrics

df=pd.read_csv(r"C:\Users\DEBIPRASAD\Desktop\Projetc Work\Loan Prediction\train_ctrUa4K.csv")
df1=pd.read_csv(r"C:\Users\DEBIPRASAD\Desktop\Projetc Work\Loan Prediction\sample_submission_49d68Cx.csv")
df.info()
#print(df.head())

useless=["Loan_ID"]
df.drop(useless,axis=1,inplace=True)

df.head()

"""#EDA
#Visualization of Various Features with the Output
"""

boolean_category=['Gender','Married','Education','Self_Employed','Loan_Amount_Term','Credit_History','Property_Area']
int_category=['ApplicantIncome','CoapplicantIncome','LoanAmount']

#print(boolean_category)
#print(int_category)

fig,axes=plt.subplots(4,2,figsize=(12,15))
for index,column in enumerate(boolean_category):
    row,col=index//2,index%2
    sns.countplot(x=column,data=df,hue='Loan_Status',ax=axes[row,col])
plt.subplots_adjust(hspace=1)

fig,axes=plt.subplots(1,3,figsize=(17,5))
for index,column in enumerate(int_category):
    sns.boxplot(y=column,x='Loan_Status',data=df,ax=axes[index])
plt.subplots_adjust(hspace=2)
plt.show()

"""Similar to Apply LabelEncoder() and OneHotEncoder() in the Data"""
df_encoded=pd.get_dummies(df,drop_first=True)
y=df_encoded["Loan_Status_Y"]
x=df_encoded.drop('Loan_Status_Y',axis=1)

"""#TEST SET
#The Real One Given in Hackathon
"""



"""#SPLITING OF THE TRAINING SET
#Training Set and the Cross-Validation Set
"""

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,stratify=y,random_state=42)

'''Taking Care of NaN datas and the Other Missing Datas'''
'''We are using Mean Strategy to Overcome this'''
imp=SimpleImputer(strategy='mean')
imp_train=imp.fit(x_train)
x_train=imp_train.transform(x_train)
x_test=imp_train.transform(x_test)


"""TRYING DECISION_TREE CLASSIFIER"""
max_depth=20
dict_depth=[]

depth=[]
tr_acc=[]
ts_acc=[]
for i in range(1,max_depth+1):
    dtc=DecisionTreeClassifier(max_depth=i,random_state=42)
    dtc.fit(x_train,y_train)
    y_train_pred=dtc.predict(x_train)
    y_test_pred=dtc.predict(x_test)
    #print("Depth",i)
    #print("Train_Set",metrics.accuracy_score(y_train,y_train_pred))
    #print("Test_Set",metrics.accuracy_score(y_test,y_test_pred))
    depth.append(i)
    tr_acc.append(metrics.accuracy_score(y_train,y_train_pred))
    ts_acc.append(metrics.accuracy_score(y_test,y_test_pred))
    
plt.plot(depth,tr_acc,ts_acc)
plt.xlabel('Depth')
plt.ylabel('Accuracy_Score')
plt.legend(labels=('Train Accuracy','Test Accuracy'))
plt.show()